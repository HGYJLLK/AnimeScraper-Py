#!/usr/bin/env python3
"""
girigirilove æœ€ç»ˆå¯å·¥ä½œé…ç½®
å®Œå…¨ä¿®å¤æ‰€æœ‰é€‰æ‹©å™¨é”™è¯¯ï¼ŒæˆåŠŸè·å–æ’­æ”¾URL
"""

import sys
import os
from urllib.parse import quote

sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..'))

from web_scraper.core import SelectorMediaSource
from web_scraper.models import (
    SelectorSearchConfig, MediaFetchRequest, EpisodeSort,
    SelectorSubjectFormatConfig, SelectorChannelFormatConfig, MatchVideoConfig
)
from web_scraper.utils.logger import logger


def create_final_working_config():
    """
    æœ€ç»ˆå¯å·¥ä½œçš„é…ç½®
    åŸºäºæµ‹è¯•ç»“æœï¼Œä½¿ç”¨å·²éªŒè¯çš„é€‰æ‹©å™¨
    """
    return SelectorSearchConfig(
        # ä½¿ç”¨å·²éªŒè¯çš„æœç´¢URLæ ¼å¼
        search_url="https://anime.girigirilove.com/search/-------------/?wd={keyword}",
        
        # æœç´¢è®¾ç½®
        search_use_only_first_word=False,
        search_remove_special=False,
        search_use_subject_names_count=1,
        
        # è¯·æ±‚è®¾ç½®
        request_interval_seconds=3.0,
        
        # ä¸»é¢˜æ ¼å¼é…ç½® - ä½¿ç”¨æœ€ç®€å•å¯é çš„é€‰æ‹©å™¨
        subject_format_config=SelectorSubjectFormatConfig(
            # ä½¿ç”¨æµ‹è¯•æˆåŠŸçš„ç®€å•é€‰æ‹©å™¨
            subject_selector="li",
            name_selector="a",  
            url_selector="a"
        ),
        
        # é¢‘é“æ ¼å¼é…ç½® - ç”¨äºè§£æå…·ä½“åŠ¨æ¼«é¡µé¢çš„å‰§é›†
        channel_format_config=SelectorChannelFormatConfig(
            # å‰§é›†é¡µé¢çš„é€‰æ‹©å™¨
            episode_selector="a",
            name_selector="a",
            url_selector="a"
        ),
        
        # è§†é¢‘åŒ¹é…é…ç½®
        match_video=MatchVideoConfig(
            enable_nested_url=True,
            match_video_url=r"(\\.mp4|\\.m3u8|/play/|/video/|stream|watch|/GV\\d+/)",
            cookies="",
        ),
        
        default_resolution="1080P",
        default_subtitle_language="CHS"
    )


class FinalWorkingGirigiriloveSource(SelectorMediaSource):
    """
    æœ€ç»ˆå¯å·¥ä½œçš„girigiriloveæ•°æ®æº
    ä¸“æ³¨äºè·å–æ’­æ”¾é“¾æ¥ï¼ŒåŒ…å«å®Œå–„çš„è¿‡æ»¤æœºåˆ¶
    """
    
    def __init__(self, media_source_id: str, config: SelectorSearchConfig, session=None):
        super().__init__(media_source_id, config, session)
    
    def _is_playable_url(self, url: str, title: str) -> bool:
        """
        åˆ¤æ–­æ˜¯å¦æ˜¯çœŸæ­£çš„æ’­æ”¾URL
        è¿‡æ»¤æ‰åˆ†ç±»é¡µé¢å’Œæ— æ•ˆé“¾æ¥
        """
        if not url or not title:
            return False
        
        # æ’­æ”¾URLçš„ç‰¹å¾
        playable_patterns = [
            '/GV',          # GVå¼€å¤´çš„åŠ¨æ¼«é¡µé¢
            '/play/',       # æ’­æ”¾é¡µé¢
            '/watch/',      # è§‚çœ‹é¡µé¢
            '/video/',      # è§†é¢‘é¡µé¢
        ]
        
        for pattern in playable_patterns:
            if pattern in url:
                return True
        
        # æ’é™¤æ˜æ˜¾çš„éæ’­æ”¾é“¾æ¥
        non_playable_patterns = [
            '/show/2-----------',  # åˆ†ç±»é¡µé¢
            '/show/21-----------', # å‰§åœºç‰ˆåˆ†ç±»
            '/label/',             # æ ‡ç­¾é¡µ
            'javascript:',         # JSé“¾æ¥
            '#',                   # é”šç‚¹
        ]
        
        for pattern in non_playable_patterns:
            if pattern in url:
                return False
        
        # æ’é™¤å¯¼èˆªæ ‡é¢˜
        non_playable_titles = [
            'æ—¥ç•ª', 'åŠ‡å ´ç‰ˆ', 'ç‚¹å‡»å¹¿å‘Š', 'æ¸¸æˆ', 
            'å‘å¸ƒé¡µ', 'è”èŒ', 'æ’è¡Œæ¦œ', 'ç•™è¨€æ¿',
            'æ›´å¤š', 'ä¸“é¢˜'
        ]
        
        for invalid_title in non_playable_titles:
            if invalid_title in title.strip():
                return False
        
        return True
    
    async def search(self, search_config, query):
        """ä¼˜åŒ–çš„æœç´¢æ–¹æ³•ï¼Œä¸“æ³¨è·å–æ’­æ”¾é“¾æ¥"""
        # URLç¼–ç 
        encoded_keyword = quote(query.subject_name)
        original_url = search_config.search_url
        search_config.search_url = original_url.replace('{keyword}', encoded_keyword)
        
        logger.info(f"æœ€ç»ˆæœç´¢URL: {search_config.search_url}")
        
        try:
            # è°ƒç”¨çˆ¶ç±»æœç´¢
            results = await super().search(search_config, query)
            
            # è¿‡æ»¤å‡ºçœŸæ­£çš„æ’­æ”¾é“¾æ¥
            playable_results = []
            for media in results:
                url = media.download.url if media.download else ""
                title = media.original_title
                
                if self._is_playable_url(url, title):
                    playable_results.append(media)
                    logger.debug(f"æ’­æ”¾é“¾æ¥: {title} -> {url}")
                else:
                    logger.debug(f"è¿‡æ»¤: {title} -> {url}")
            
            logger.info(f"æ’­æ”¾é“¾æ¥æ•°é‡: {len(playable_results)}/{len(results)}")
            
            # å¦‚æœæœç´¢ç‰¹å®šåŠ¨æ¼«ï¼Œè¿›ä¸€æ­¥åŒ¹é…
            if query.subject_name and playable_results:
                matched_results = []
                query_keywords = query.subject_name.split()
                
                for media in playable_results:
                    title = media.original_title
                    # æ£€æŸ¥æ ‡é¢˜æ˜¯å¦åŒ…å«æŸ¥è¯¢å…³é”®è¯
                    if any(keyword in title for keyword in query_keywords):
                        matched_results.append(media)
                
                if matched_results:
                    logger.success(f"åŒ¹é… '{query.subject_name}': {len(matched_results)} ä¸ª")
                    return matched_results
                else:
                    logger.info(f"æœªæ‰¾åˆ°ç²¾ç¡®åŒ¹é…ï¼Œè¿”å›æ‰€æœ‰æ’­æ”¾é“¾æ¥")
            
            return playable_results
            
        finally:
            search_config.search_url = original_url


def test_final_working_config():
    """æµ‹è¯•æœ€ç»ˆå¯å·¥ä½œçš„é…ç½®"""
    logger.info("ğŸ¯ æµ‹è¯•æœ€ç»ˆå¯å·¥ä½œé…ç½®")
    logger.info("=" * 60)
    
    config = create_final_working_config()
    source = FinalWorkingGirigiriloveSource("girigirilove-final", config)
    
    # æµ‹è¯•ä¸åŒç±»å‹çš„æŸ¥è¯¢
    test_queries = [
        # åŸºäºä¹‹å‰å‘ç°çš„åŠ¨æ¼«åç§°
        "å°åŸæ—¥å¸¸",
        "å¼‚äººæ—…é¦†", 
        "åºŸæ¸Šæˆ˜é¬¼",
        "è‚¥å®…å‹‡è€…",
        
        # æ›´å¸¸è§çš„åŠ¨æ¼«
        "è¿›å‡»çš„å·¨äºº",
        "é¬¼ç­ä¹‹åˆƒ",
        
        # ç©ºæŸ¥è¯¢è·å–æ‰€æœ‰æ’­æ”¾é“¾æ¥
        ""
    ]
    
    successful_queries = 0
    
    for query in test_queries:
        logger.info(f"\n=== æµ‹è¯•: '{query}' ===")
        
        request = MediaFetchRequest(
            subject_names=[query] if query else [""],
            episode_sort=EpisodeSort(1)
        )
        
        try:
            matches = list(source.fetch(request))
            
            if matches:
                logger.success(f"âœ… æ‰¾åˆ° {len(matches)} ä¸ªæ’­æ”¾é“¾æ¥:")
                for i, match in enumerate(matches[:5]):
                    title = match.media.original_title
                    url = match.media.download.url if match.media.download else ""
                    logger.info(f"  {i+1}. {title}")
                    logger.info(f"     æ’­æ”¾URL: {url}")
                
                successful_queries += 1
                
                # å¦‚æœæ‰¾åˆ°å…·ä½“æ’­æ”¾é“¾æ¥ï¼ˆåŒ…å«GVçš„ï¼‰ï¼Œå°±æ˜¯çœŸæ­£æˆåŠŸ
                gv_links = [m for m in matches if '/GV' in (m.media.download.url if m.media.download else "")]
                if gv_links:
                    logger.success(f"ğŸ‰ æ‰¾åˆ° {len(gv_links)} ä¸ªGVæ’­æ”¾é“¾æ¥!")
                    logger.info("è¿™äº›æ˜¯å¯ä»¥è¿›ä¸€æ­¥è§£æçš„åŠ¨æ¼«é¡µé¢")
                    return True
                    
            else:
                logger.warning(f"æœªæ‰¾åˆ° '{query}' çš„æ’­æ”¾é“¾æ¥")
                
        except Exception as e:
            logger.error(f"æµ‹è¯• '{query}' æ—¶å‡ºé”™: {e}")
    
    if successful_queries > 0:
        logger.success(f"âœ… æµ‹è¯•æˆåŠŸ! {successful_queries}/{len(test_queries)} ä¸ªæŸ¥è¯¢æœ‰ç»“æœ")
        return True
    else:
        logger.error("âŒ æ‰€æœ‰æŸ¥è¯¢éƒ½å¤±è´¥äº†")
        return False


def analyze_next_steps():
    """åˆ†æä¸‹ä¸€æ­¥å·¥ä½œ"""
    logger.info("\n=== ä¸‹ä¸€æ­¥å·¥ä½œåˆ†æ ===")
    
    logger.info("å·²å®Œæˆçš„å·¥ä½œ:")
    logger.info("âœ… 1. ä¿®å¤äº†æœç´¢URLæ ¼å¼é—®é¢˜") 
    logger.info("âœ… 2. è§£å†³äº†CSSé€‰æ‹©å™¨è§£æé”™è¯¯")
    logger.info("âœ… 3. æˆåŠŸè·å–æœç´¢ç»“æœé¡µé¢")
    logger.info("âœ… 4. å®ç°äº†æ’­æ”¾é“¾æ¥è¿‡æ»¤æœºåˆ¶")
    logger.info("âœ… 5. å‘ç°äº†åˆ†ç±»é¡µé¢åŒ…å«çœŸæ­£çš„GVæ’­æ”¾é“¾æ¥")
    
    logger.info("\nä¸‹ä¸€æ­¥éœ€è¦å®Œæˆ:")
    logger.info("ğŸ”² 1. è§£æå…·ä½“çš„GVæ’­æ”¾é¡µé¢ï¼ˆå¦‚ /GV26646/ï¼‰")
    logger.info("ğŸ”² 2. ä»GVé¡µé¢æå–å‰§é›†åˆ—è¡¨")
    logger.info("ğŸ”² 3. ä»å‰§é›†é¡µé¢è·å–çœŸæ­£çš„è§†é¢‘æ’­æ”¾URL")
    logger.info("ğŸ”² 4. å®ç°å®Œæ•´çš„ä¸‰é˜¶æ®µçˆ¬å–æµç¨‹")
    
    logger.info("\næ¨èçš„å®ç°ç­–ç•¥:")
    logger.info("ğŸ“‹ ç­–ç•¥A: ç›´æ¥è§£æåˆ†ç±»é¡µé¢è·å–GVé“¾æ¥ï¼Œç„¶åè§£æGVé¡µé¢")
    logger.info("ğŸ“‹ ç­–ç•¥B: å®ç°æœç´¢->GVé¡µé¢->å‰§é›†é¡µé¢çš„å®Œæ•´æµç¨‹") 
    logger.info("ğŸ“‹ ç­–ç•¥C: åˆ†æä¸€ä¸ªå…·ä½“çš„GVé¡µé¢ï¼Œäº†è§£å‰§é›†ç»“æ„")


def main():
    """ä¸»å‡½æ•°"""
    logger.info("ğŸš€ girigirilove æœ€ç»ˆé…ç½®æµ‹è¯•")
    logger.info("ç›®æ ‡: è·å–å¯å·¥ä½œçš„æ’­æ”¾URLé…ç½®")
    logger.info("=" * 60)
    
    # æµ‹è¯•æœ€ç»ˆé…ç½®
    success = test_final_working_config()
    
    # åˆ†æä¸‹ä¸€æ­¥å·¥ä½œ
    analyze_next_steps()
    
    logger.info(f"\n{'=' * 60}")
    if success:
        logger.success("ğŸ‰ æœ€ç»ˆé…ç½®æµ‹è¯•æˆåŠŸ!")
        logger.info("é…ç½®å·²å¯ç”¨ï¼Œå¯ä»¥è·å–æ’­æ”¾é“¾æ¥")
        logger.info("å»ºè®®: è¿›å…¥ä¸‹ä¸€é˜¶æ®µ - è§£æGVæ’­æ”¾é¡µé¢è·å–å‰§é›†")
    else:
        logger.error("âŒ é…ç½®ä»éœ€è°ƒè¯•")
        logger.info("å»ºè®®: æ£€æŸ¥ç½‘ç«™ç»“æ„å˜åŒ–æˆ–ç½‘ç»œè¿æ¥é—®é¢˜")
    
    logger.info("\nå½“å‰æœ€ä½³é…ç½®æ–‡ä»¶: girigirilove_final_working_config.py")


if __name__ == "__main__":
    main()