#!/usr/bin/env python3
"""
girigirilove åˆ†ç±»é¡µé¢é…ç½®
åŸºäºæˆåŠŸçš„åˆ†ç±»é¡µé¢æ’­æ”¾é“¾æ¥æå–
"""

import sys
import os
from urllib.parse import quote

sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..'))

from web_scraper.core import SelectorMediaSource
from web_scraper.models import (
    SelectorSearchConfig, MediaFetchRequest, EpisodeSort,
    SelectorSubjectFormatConfig, SelectorChannelFormatConfig, MatchVideoConfig
)
from web_scraper.utils.logger import logger


def create_category_config():
    """
    åŸºäºåˆ†ç±»é¡µé¢çš„é…ç½®
    ç›´æ¥ä½¿ç”¨åˆ†ç±»é¡µé¢è·å–æ’­æ”¾é“¾æ¥ï¼Œç»•è¿‡æœç´¢é—®é¢˜
    """
    return SelectorSearchConfig(
        # ä½¿ç”¨åˆ†ç±»é¡µé¢è€Œä¸æ˜¯æœç´¢é¡µé¢
        search_url="https://anime.girigirilove.com/show/2-----------2025/",
        
        # æœç´¢è®¾ç½®
        search_use_only_first_word=False,
        search_remove_special=False,
        search_use_subject_names_count=1,
        
        # è¯·æ±‚è®¾ç½®
        request_interval_seconds=3.0,
        
        # ä¸»é¢˜æ ¼å¼é…ç½® - åŸºäºæˆåŠŸçš„åˆ†ç±»é¡µé¢ç»“æ„
        subject_format_config=SelectorSubjectFormatConfig(
            # åŒ…å«GVé“¾æ¥çš„å®¹å™¨
            subject_selector="a[href*='/GV']",
            # è·å–åŠ¨æ¼«åç§°
            name_selector="self::*",
            # è·å–æ’­æ”¾é“¾æ¥
            url_selector="self::*"
        ),
        
        # é¢‘é“æ ¼å¼é…ç½® - åŠ¨æ¼«è¯¦æƒ…é¡µé¢çš„å‰§é›†åˆ—è¡¨
        channel_format_config=SelectorChannelFormatConfig(
            # å‰§é›†å®¹å™¨
            episode_selector="a[href*='/play/'], .episode-item, .play-list li",
            # å‰§é›†åç§°
            name_selector="self::*, .title, .episode-name",
            # æ’­æ”¾é“¾æ¥
            url_selector="self::*"
        ),
        
        # è§†é¢‘åŒ¹é…é…ç½®
        match_video=MatchVideoConfig(
            enable_nested_url=True,
            match_video_url=r"(\\.mp4|\\.m3u8|/play/|/video/|stream|watch|/GV\\d+/)",
            cookies="",
        ),
        
        default_resolution="1080P",
        default_subtitle_language="CHS"
    )


def create_fixed_search_config():
    """
    ä¿®å¤é€‰æ‹©å™¨é”™è¯¯çš„æœç´¢é…ç½®
    ç®€åŒ–é€‰æ‹©å™¨é¿å…è§£æé”™è¯¯
    """
    return SelectorSearchConfig(
        # ä¿®å¤åçš„æœç´¢URL
        search_url="https://anime.girigirilove.com/search/-------------/?wd={keyword}",
        
        search_use_only_first_word=False,
        search_remove_special=False,
        search_use_subject_names_count=1,
        request_interval_seconds=3.0,
        
        # ç®€åŒ–çš„é€‰æ‹©å™¨é…ç½®ï¼Œé¿å…å¤æ‚é€‰æ‹©å™¨å¯¼è‡´è§£æé”™è¯¯
        subject_format_config=SelectorSubjectFormatConfig(
            # ä½¿ç”¨ç®€å•çš„é€‰æ‹©å™¨
            subject_selector="li",
            name_selector="a",
            url_selector="a"
        ),
        
        channel_format_config=SelectorChannelFormatConfig(
            episode_selector="li",
            name_selector="a",
            url_selector="a"
        ),
        
        match_video=MatchVideoConfig(
            enable_nested_url=True,
            match_video_url=r"(\\.mp4|\\.m3u8|/play/|/video/|stream|watch|/GV\\d+/)",
            cookies="",
        ),
        
        default_resolution="1080P",
        default_subtitle_language="CHS"
    )


class CategoryGirigiriloveSource(SelectorMediaSource):
    """
    åŸºäºåˆ†ç±»é¡µé¢çš„girigiriloveæ•°æ®æº
    ç›´æ¥ä»åˆ†ç±»é¡µé¢è·å–åŠ¨æ¼«åˆ—è¡¨ï¼Œç„¶åè¿›ä¸€æ­¥è§£æ
    """
    
    def __init__(self, media_source_id: str, config: SelectorSearchConfig, session=None):
        super().__init__(media_source_id, config, session)
    
    def _build_category_url(self, keyword: str = "") -> str:
        """
        æ„å»ºåˆ†ç±»é¡µé¢URL
        å¯ä»¥æ ¹æ®å…³é”®è¯é€‰æ‹©ä¸åŒçš„åˆ†ç±»é¡µé¢
        """
        # é»˜è®¤ä½¿ç”¨2025å¹´æ—¥ç•ªé¡µé¢
        category_url = "https://anime.girigirilove.com/show/2-----------2025/"
        return category_url
    
    def _is_valid_anime_link(self, url: str, title: str) -> bool:
        """
        éªŒè¯æ˜¯å¦æ˜¯æœ‰æ•ˆçš„åŠ¨æ¼«æ’­æ”¾é“¾æ¥
        """
        if not url or not title:
            return False
            
        # æ£€æŸ¥æ˜¯å¦åŒ…å«GV IDï¼ˆæ’­æ”¾é“¾æ¥çš„ç‰¹å¾ï¼‰
        if '/GV' in url:
            return True
            
        return False
    
    async def search(self, search_config, query):
        """è¦†ç›–æœç´¢æ–¹æ³•ï¼Œç›´æ¥è®¿é—®åˆ†ç±»é¡µé¢"""
        category_url = self._build_category_url(query.subject_name)
        
        # ä¸´æ—¶æ›¿æ¢æœç´¢URLä¸ºåˆ†ç±»é¡µé¢URL
        original_url = search_config.search_url
        search_config.search_url = category_url
        
        logger.info(f"è®¿é—®åˆ†ç±»é¡µé¢: {search_config.search_url}")
        
        try:
            # è°ƒç”¨çˆ¶ç±»æœç´¢æ–¹æ³•
            results = await super().search(search_config, query)
            
            # è¿‡æ»¤å‡ºæœ‰æ•ˆçš„æ’­æ”¾é“¾æ¥
            valid_results = []
            for media in results:
                url = media.download.url if media.download else ""
                title = media.original_title
                
                if self._is_valid_anime_link(url, title):
                    valid_results.append(media)
                    logger.debug(f"æœ‰æ•ˆæ’­æ”¾é“¾æ¥: {title} -> {url}")
            
            logger.info(f"æ‰¾åˆ°æœ‰æ•ˆæ’­æ”¾é“¾æ¥: {len(valid_results)}/{len(results)}")
            
            # å¦‚æœæŸ¥è¯¢ç‰¹å®šåŠ¨æ¼«ï¼Œå°è¯•åŒ¹é…
            if query.subject_name:
                matched_results = []
                query_lower = query.subject_name.lower()
                for media in valid_results:
                    title_lower = media.original_title.lower()
                    if query_lower in title_lower or any(char in title_lower for char in query.subject_name):
                        matched_results.append(media)
                
                if matched_results:
                    logger.success(f"åŒ¹é…åˆ° '{query.subject_name}' ç›¸å…³ç»“æœ: {len(matched_results)} ä¸ª")
                    return matched_results
            
            return valid_results
            
        finally:
            # æ¢å¤åŸå§‹URL
            search_config.search_url = original_url


class FixedSearchGirigiriloveSource(SelectorMediaSource):
    """
    ä¿®å¤é€‰æ‹©å™¨é”™è¯¯çš„æœç´¢æ•°æ®æº
    ä½¿ç”¨ç®€åŒ–çš„é€‰æ‹©å™¨é¿å…è§£æé”™è¯¯
    """
    
    def __init__(self, media_source_id: str, config: SelectorSearchConfig, session=None):
        super().__init__(media_source_id, config, session)
    
    async def search(self, search_config, query):
        """ä¿®å¤é€‰æ‹©å™¨é”™è¯¯çš„æœç´¢æ–¹æ³•"""
        # å¯¹å…³é”®è¯è¿›è¡ŒURLç¼–ç 
        encoded_keyword = quote(query.subject_name)
        original_url = search_config.search_url
        search_config.search_url = original_url.replace('{keyword}', encoded_keyword)
        
        logger.info(f"ä¿®å¤åçš„æœç´¢URL: {search_config.search_url}")
        
        try:
            results = await super().search(search_config, query)
            return results
        finally:
            search_config.search_url = original_url


def test_category_approach():
    """æµ‹è¯•åˆ†ç±»é¡µé¢æ–¹æ³•"""
    logger.info("ğŸ¯ æµ‹è¯•åˆ†ç±»é¡µé¢æ–¹æ³•")
    logger.info("=" * 60)
    
    config = create_category_config()
    source = CategoryGirigiriloveSource("girigirilove-category", config)
    
    # æµ‹è¯•ä¸åŒçš„æŸ¥è¯¢
    test_queries = [
        "å°åŸ",      # åŸºäºå‘ç°çš„ "å°åŸæ—¥å¸¸"
        "å¼‚äºº",      # åŸºäºå‘ç°çš„ "å¼‚äººæ—…é¦†"
        "åºŸæ¸Š",      # åŸºäºå‘ç°çš„ "åºŸæ¸Šæˆ˜é¬¼"
        ""           # ç©ºæŸ¥è¯¢ï¼Œè·å–æ‰€æœ‰ç»“æœ
    ]
    
    for query in test_queries:
        logger.info(f"\n=== æµ‹è¯•æŸ¥è¯¢: '{query}' ===")
        
        request = MediaFetchRequest(
            subject_names=[query] if query else [""],
            episode_sort=EpisodeSort(1)
        )
        
        try:
            matches = list(source.fetch(request))
            
            if matches:
                logger.success(f"âœ… æ‰¾åˆ° {len(matches)} ä¸ªç»“æœ:")
                for i, match in enumerate(matches[:5]):
                    title = match.media.original_title
                    url = match.media.download.url if match.media.download else ""
                    logger.info(f"  {i+1}. {title}")
                    logger.info(f"     URL: {url}")
                
                # æ‰¾åˆ°ç»“æœå°±æµ‹è¯•æˆåŠŸ
                logger.success("ğŸ‰ åˆ†ç±»é¡µé¢æ–¹æ³•æˆåŠŸ!")
                return True
                
            else:
                logger.warning(f"æœªæ‰¾åˆ° '{query}' çš„ç»“æœ")
                
        except Exception as e:
            logger.error(f"æµ‹è¯• '{query}' æ—¶å‡ºé”™: {e}")
    
    return False


def test_fixed_search():
    """æµ‹è¯•ä¿®å¤çš„æœç´¢åŠŸèƒ½"""
    logger.info("\nğŸ”§ æµ‹è¯•ä¿®å¤çš„æœç´¢åŠŸèƒ½")
    logger.info("=" * 60)
    
    config = create_fixed_search_config()
    source = FixedSearchGirigiriloveSource("girigirilove-fixed", config)
    
    # ä½¿ç”¨åœ¨åˆ†ç±»é¡µé¢ä¸­å‘ç°çš„åŠ¨æ¼«åç§°è¿›è¡Œæœç´¢
    test_queries = [
        "å°åŸæ—¥å¸¸",
        "å¼‚äººæ—…é¦†",
        "åºŸæ¸Šæˆ˜é¬¼"
    ]
    
    for query in test_queries:
        logger.info(f"\n=== ä¿®å¤æœç´¢æµ‹è¯•: {query} ===")
        
        request = MediaFetchRequest(
            subject_names=[query],
            episode_sort=EpisodeSort(1)
        )
        
        try:
            matches = list(source.fetch(request))
            
            if matches:
                logger.success(f"âœ… æœç´¢æˆåŠŸ! æ‰¾åˆ° {len(matches)} ä¸ªç»“æœ:")
                for i, match in enumerate(matches[:3]):
                    title = match.media.original_title
                    url = match.media.download.url if match.media.download else ""
                    logger.info(f"  {i+1}. {title}")
                    logger.info(f"     URL: {url}")
                
                logger.success("ğŸ‰ ä¿®å¤çš„æœç´¢æ–¹æ³•æˆåŠŸ!")
                return True
                
            else:
                logger.warning(f"æœç´¢ '{query}' æ— ç»“æœ")
                
        except Exception as e:
            logger.error(f"æœç´¢ '{query}' æ—¶å‡ºé”™: {e}")
    
    return False


def main():
    """ä¸»å‡½æ•°"""
    logger.info("ğŸš€ girigirilove åˆ†ç±»é¡µé¢é…ç½®æµ‹è¯•")
    logger.info("åŸºäºæˆåŠŸçš„åˆ†ç±»é¡µé¢å‘ç°ç»“æœ")
    logger.info("=" * 60)
    
    # é¦–å…ˆæµ‹è¯•åˆ†ç±»é¡µé¢æ–¹æ³•
    category_success = test_category_approach()
    
    # ç„¶åæµ‹è¯•ä¿®å¤çš„æœç´¢æ–¹æ³•
    search_success = test_fixed_search()
    
    logger.info(f"\n{'=' * 60}")
    logger.success("æµ‹è¯•å®Œæˆ!")
    
    if category_success:
        logger.success("âœ… åˆ†ç±»é¡µé¢æ–¹æ³•å¯ç”¨ - æ¨èä½¿ç”¨")
        logger.info("ä¼˜åŠ¿: ç›´æ¥è®¿é—®åˆ†ç±»é¡µé¢ï¼Œè·å–çœŸå®çš„æ’­æ”¾é“¾æ¥")
    
    if search_success:
        logger.success("âœ… ä¿®å¤æœç´¢æ–¹æ³•å¯ç”¨")
        logger.info("ä¼˜åŠ¿: æ”¯æŒå…³é”®è¯æœç´¢ç‰¹å®šåŠ¨æ¼«")
    
    if not category_success and not search_success:
        logger.error("âŒ ä¸¤ç§æ–¹æ³•éƒ½æœªæˆåŠŸ")
        logger.info("å»ºè®®: è¿›ä¸€æ­¥åˆ†æç½‘ç«™ç»“æ„æˆ–ä½¿ç”¨å…¶ä»–æ–¹æ³•")
    
    logger.info("\nä¸‹ä¸€æ­¥å»ºè®®:")
    logger.info("1. ä½¿ç”¨æˆåŠŸçš„æ–¹æ³•è¿›ä¸€æ­¥è§£æå‰§é›†é¡µé¢")
    logger.info("2. åˆ†æ /GV é“¾æ¥é¡µé¢çš„ç»“æ„è·å–å…·ä½“æ’­æ”¾URL")
    logger.info("3. å®ç°å®Œæ•´çš„æ’­æ”¾é“¾æ¥æå–æµç¨‹")


if __name__ == "__main__":
    main()